{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BobGanti/ColabNotebooks/blob/main/pdf_to_text_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjgiuTnrm7NQ"
      },
      "source": [
        "## Unstructured To Structured Dataset Creation With Few-Shot Learning Of Gen Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtKP_p0vsaXX",
        "outputId": "2673ab19-b005-490a-f9a9-d5af33dec3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.9/335.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q imbalanced-learn \\\n",
        "PyMuPDF \\\n",
        "openai \\\n",
        "PyPDF2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4ptB4BJYlqD",
        "outputId": "00f46cc7-22c4-409f-d335-fba9a0eac6ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import openai\n",
        "import PyPDF2\n",
        "import pymupdf\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pickle\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXxEttwfr4Wo",
        "outputId": "feec1cea-7035-4d46-fe76-6cd8756ab1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, userdata\n",
        "drive = drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DATA_DIR = userdata.get('ROOT_DIR')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "arxiv_DIR = DATA_DIR + \"/arxiv\"\n",
        "PDF_DIR = arxiv_DIR + \"/PDFs\"\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRR3Tr1tYlrs"
      },
      "source": [
        "### Questions Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_oHnla0MkvMg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import csv\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def generate_question(text_chunk):\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in analysing text, determining the context and topic being discussed in the text and generating relevant question.\n",
        "    Learn from the given examples 1, 2, 3. Then analyse the given text chunk and generate the most appropriate question with 100% cosine similarity and BM25r can be extracted from the text chunk.\n",
        "\n",
        "    Example 1:\n",
        "    Text: 'Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.'\n",
        "    Question: What issue do large language models (LLMs) inevitably exhibit, and what is a concern related to retrieval-augmented generation (RAG)?\n",
        "    Similarity Score: 0.9327\n",
        "\n",
        "    Example 2:\n",
        "    Text: 'To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered.'\n",
        "    Question: What is the purpose of the Corrective Retrieval Augmented Generation (CRAG) and what specific component is designed to assess the quality of retrieved documents?\n",
        "    Similarity Score: 0.9864\n",
        "\n",
        "    Example 3:\n",
        "    Text: 'Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them.'\n",
        "    Question: What method is proposed to augment the retrieval results from static and limited corpora, and what algorithm is designed to process the retrieved documents?\n",
        "    similarity Score: 0.9379\n",
        "\n",
        "    Now, read the following text chunk and generate the most appropriate question:\n",
        "\n",
        "    Text: '{text_chunk}'\n",
        "    Question:\n",
        "    \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in question generator.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=100,\n",
        "        temperature=0.5,\n",
        "        n=1,\n",
        "        stop=None\n",
        "    )\n",
        "    question = str(response.choices[0].message.content).strip()\n",
        "    return question\n",
        "\n",
        "def generate_text(question, label):\n",
        "    if label == 'ambiguous':\n",
        "        prompt = f\"\"\"\n",
        "        Generate a text chunk that somewhat relates to the following question but can only provide context that captures only less than 50% down to 15% of the potential answer.\n",
        "\n",
        "        Example 1:\n",
        "        Question: What issue do large language models (LLMs) inevitably exhibit, and what is a concern related to retrieval-augmented generation (RAG)?\n",
        "        Text: Advances in large language models often pivot around optimizing computational efficiency and reducing energy consumption. These models are increasingly deployed in real-time applications, where their ability to adapt to streaming data becomes paramount, diverging from concerns typically associated with static data sets.\n",
        "        Cosine Similarity Score: 38.82%\n",
        "\n",
        "        Example 2:\n",
        "        Question: What is the purpose of the Corrective Retrieval Augmented Generation (CRAG) and what specific component is designed to assess the quality of retrieved documents?\n",
        "        Text: The exploration of new algorithms in text generation frequently targets the enhancement of linguistic diversity and the reduction of biases. Key components often involve neural network architectures that focus on generative adversarial networks, which work to create more nuanced and varied text outputs.\n",
        "        Cosine Similarity Score: 33.18%\n",
        "\n",
        "        Example 3:\n",
        "        Question: What method is proposed to augment the retrieval results from static and limited corpora, and what algorithm is designed to process the retrieved documents?\n",
        "        Text: Current trends in database management focus on improving security protocols and data encryption methods to safeguard information against cyber threats. Enhanced security measures include the implementation of advanced encryption standards and real-time intrusion detection systems.\n",
        "        Cosine Similarity Score: 24.83%\n",
        "\n",
        "        Example 4:\n",
        "        Question: How is CRAG described in terms of integration with RAG-based approaches, and what do experiments show about its performance?\n",
        "        Text: Discussions around CRAG often shift towards its potential applications in non-text-based fields, such as super market stuff recognition and video analysis. These applications explore how cross-modal data integration can lead to more robust models, with experiments often delving into the use of deep learning for feature extraction.\n",
        "        Cosine Similarity Score: 50%\n",
        "\n",
        "        Now, read the following question and generate a somewhat related text chunk:\n",
        "\n",
        "        Question: \"{question}\"\n",
        "        Text:\n",
        "        \"\"\"\n",
        "    elif label == 'irrelevant':\n",
        "        prompt = f\"\"\"\n",
        "        Generate a text chunk that is not related to the following question and cannot be answered based on the text.\n",
        "\n",
        "        Example 1:\n",
        "        Question: What issue do large language models (LLMs) inevitably exhibit, and what is a concern related to retrieval-augmented generation (RAG)?\n",
        "        Text: Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with the help of chlorophyll. This process is crucial for converting solar energy into chemical energy.\n",
        "\n",
        "        Example 2:\n",
        "        Question: What is the purpose of the Corrective Retrieval Augmented Generation (CRAG) and what specific component is designed to assess the quality of retrieved documents?\n",
        "        Text: The Roman Empire's history is marked by significant events and figures that shaped Western civilization. From the rise of Julius Caesar to the fall of the empire, each period offers insights into the complexities of ancient governance.\n",
        "\n",
        "        Example 3:\n",
        "        Question: What method is proposed to augment the retrieval results from static and limited corpora, and what algorithm is designed to process the retrieved documents?\n",
        "        Text: Quantum mechanics explores the behavior of particles at the atomic and subatomic levels. It reveals the fundamental principles governing the interactions and properties of matter and energy, challenging classical physics notions.\n",
        "\n",
        "        Example 4:\n",
        "        Question: How is CRAG described in terms of integration with RAG-based approaches, and what do experiments show about its performance?\n",
        "        Text: Marine biology studies the ecosystems and organisms within the ocean. Researchers focus on understanding marine life forms, their interactions, and the impact of human activities on marine environments.\n",
        "\n",
        "        Now, read the following question and generate an unrelated text chunk:\n",
        "\n",
        "        Question: \"{question}\"\n",
        "        Text:\n",
        "        \"\"\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid label. Must be 'ambiguous' or 'irrelevant'.\")\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in text generation.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=150,\n",
        "        temperature=0.5,\n",
        "        n=1,\n",
        "        stop=None\n",
        "    )\n",
        "\n",
        "    return str(response.choices[0].message.content).strip()\n",
        "\n",
        "def calculate_relevance_score_gpt(question, text):\n",
        "    prompt = f\"\"\"\n",
        "    Evaluate the relevance of the following text in answering the given question. Provide a score (value only with no text) between 0 and 100, where 100 means completely relevant and 0 means completely irrelevant.\n",
        "\n",
        "    Question: {question}\n",
        "    Text: {text}\n",
        "    Score:\n",
        "    \"\"\"\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an expert in evaluating text relevance.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        max_tokens=10,\n",
        "        temperature=0.5,\n",
        "        n=1,\n",
        "        stop=[\"Score:\"]\n",
        "    )\n",
        "\n",
        "    score = str(response.choices[0].message.content).strip()\n",
        "    return score\n",
        "\n",
        "# test\n",
        "question = \"What issue do large language models (LLMs) face regarding the accuracy of generated texts, and what concern is associated with retrieval-augmented generation (RAG)?\"\n",
        "text_chunk = \"Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.\"\n",
        "score = calculate_relevance_score_gpt(question, text_chunk)\n",
        "print(f\"Relevance score: {score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9qstDqzk4i6"
      },
      "source": [
        "### OpenSource Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbmPCPC4oCXQ"
      },
      "source": [
        "### With All Mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_EFDRjdkftr",
        "outputId": "d0a4ac62-7333-4526-ca1f-c71f5b43357e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevance score: 95\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the pre-trained model and tokenizer\n",
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "def get_embeddings(texts):\n",
        "    \"\"\"Get embeddings for a list of texts using a pre-trained model.\"\"\"\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        model_output = model(**inputs)\n",
        "    embeddings = model_output.last_hidden_state.mean(dim=1)\n",
        "    return embeddings\n",
        "\n",
        "def calculate_relevance_score_mini(question, text_chunk):\n",
        "    \"\"\"Calculate the relevance score between a question and a text chunk.\"\"\"\n",
        "    embeddings = get_embeddings([question, text_chunk])\n",
        "    question_embedding = embeddings[0].unsqueeze(0)\n",
        "    text_chunk_embedding = embeddings[1].unsqueeze(0)\n",
        "    score = cosine_similarity(question_embedding, text_chunk_embedding)[0][0]\n",
        "    return score\n",
        "\n",
        "# test\n",
        "question = \"What issue do large language models (LLMs) face regarding the accuracy of generated texts, and what concern is associated with retrieval-augmented generation (RAG)?\"\n",
        "text_chunk = \"Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.\"\n",
        "score = calculate_relevance_score_mini(question, text_chunk)\n",
        "print(f\"Relevance score: {score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNJJm59toLw2"
      },
      "source": [
        "### With BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE78ILFIbjpO"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to calculate BERT-based similarity\n",
        "def calculate_bert_similarity(question, text):\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    # Encode the texts\n",
        "    encoded_text = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    encoded_question = tokenizer(question, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    with torch.no_grad():\n",
        "        text_embeddings = model(**encoded_text).pooler_output\n",
        "        question_embeddings = model(**encoded_question).pooler_output\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarity = cosine_similarity(text_embeddings, question_embeddings)[0][0]\n",
        "    return similarity\n",
        "\n",
        "# test\n",
        "question = \"What issue do large language models (LLMs) face regarding the accuracy of generated texts, and what concern is associated with retrieval-augmented generation (RAG)?\"\n",
        "text_chunk = \"Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong.\"\n",
        "score = calculate_relevance_score_gpt(question, text_chunk)\n",
        "print(f\"Relevance score: {score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3br9xbgcoRcQ"
      },
      "source": [
        "### Creating The Documents From PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27ACVg7UPt0B"
      },
      "outputs": [],
      "source": [
        "import pymupdf\n",
        "import os\n",
        "import re\n",
        "\n",
        "def extract_text_from_pdf(file_path):\n",
        "    # Open the PDF file\n",
        "    pdf_document = pymupdf.open(file_path)\n",
        "    text = \"\"\n",
        "\n",
        "    # Extracting text from each page\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document[page_num]\n",
        "        text += page.get_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "    # Defining patterns to exclude sections like References\n",
        "    exclude_patterns = [\n",
        "        r'\\bReferences\\b.*',  # Matching \"References\" and everything after\n",
        "        r'\\bBibliography\\b.*',  # Matching \"Bibliography\" and everything after\n",
        "         r'^\\s*$',  # Matching empty lines\n",
        "    ]\n",
        "    for pattern in exclude_patterns:\n",
        "        text = re.sub(pattern, '', text, flags=re.DOTALL)\n",
        "\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, chunk_size=300, overlap=50):\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(words):\n",
        "        end = min(start + chunk_size, len(words))\n",
        "        chunk = words[start:end]\n",
        "        chunks.append(' '.join(chunk))\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "def process_pdfs_in_directory(directory_path):\n",
        "    document_texts = []\n",
        "    for filename in os.listdir(directory_path):\n",
        "        if filename.lower().endswith('.pdf'):\n",
        "            file_path = os.path.join(directory_path, filename)\n",
        "            text = extract_text_from_pdf(file_path)\n",
        "            cleaned_text = clean_text(text)\n",
        "            chunks = chunk_text(cleaned_text)\n",
        "            document_texts.append(\n",
        "                {'metadata':file_path,\n",
        "                 'title':filename,\n",
        "                 'chunks':chunks\n",
        "                }\n",
        "            )\n",
        "    return document_texts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzJW6NGvodBv"
      },
      "source": [
        "### The QC (Question-Context) Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m99mkP3mmxLW",
        "outputId": "c9cd795e-c97d-4d1f-d6ad-e65c17bf36a5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text extraction, cleaning, and chunking complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "directory_path = PDF_DIR\n",
        "document_texts = process_pdfs_in_directory(directory_path)\n",
        "\n",
        "qc = []\n",
        "for doc_text in document_texts:\n",
        "    for i, chunk in enumerate(doc_text['chunks']):\n",
        "        text_filename = doc_text['title'].replace('.pdf', f'_{i+1}.txt')\n",
        "        with open(os.path.join(directory_path, text_filename), 'w', encoding='utf-8') as text_file:\n",
        "            text_file.write(chunk)\n",
        "\n",
        "        doc_question = generate_question(chunk)\n",
        "        qc.append({'question': doc_question, 'context': chunk})\n",
        "\n",
        "print(\"Text extraction, cleaning, and chunking complete.\")\n",
        "\n",
        "\n",
        "for doc in document_texts:\n",
        "    for chunk in doc['chunks']:\n",
        "        doc_question = generate_question(chunk)\n",
        "        qc.append(\n",
        "            {\n",
        "                'question': doc_question,\n",
        "                'context': chunk\n",
        "            }\n",
        "        )\n",
        "\n",
        "data = pd.DataFrame(qc)\n",
        "data.to_csv(DATA_DIR+'/arxiv_finetuning_qa.csv', index=False, escapechar='\\\\')\n",
        "\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEFL1b64P2M2"
      },
      "source": [
        "#### Load Locally Save QC Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxVk984OFNwm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def build_records(qa, thresholds):\n",
        "    dataset = []\n",
        "    label = \"\"\n",
        "    questions = qa['question'].tolist()\n",
        "    contexts = qa['context'].tolist()\n",
        "\n",
        "    for i, q in enumerate(questions):\n",
        "        rel_record = {\n",
        "            \"question\": q,\n",
        "            \"context\": contexts[i],\n",
        "            \"score\": int(calculate_relevance_score_gpt(q, contexts[i])),\n",
        "            \"label\": \"relevant\"\n",
        "        }\n",
        "        dataset.append(rel_record)\n",
        "\n",
        "        amb_text = generate_text(q, 'ambiguous')\n",
        "        amb_score = int(calculate_relevance_score_gpt(q, amb_text))\n",
        "        if amb_score >= thresholds[1]:\n",
        "            label = 'relevant'\n",
        "        elif thresholds[0] <= amb_score < thresholds[1]:\n",
        "            label = 'ambiguous'\n",
        "        else: label = 'irrelevant'\n",
        "\n",
        "        amb_record = {\n",
        "            \"question\": q,\n",
        "            \"context\": amb_text,\n",
        "            \"score\": amb_score,\n",
        "            \"label\": label\n",
        "        }\n",
        "        dataset.append(amb_record)\n",
        "\n",
        "        irr_text = generate_text(q, 'irrelevant')\n",
        "        irr_score = int(calculate_relevance_score_gpt(q, irr_text))\n",
        "        if irr_score >= thresholds[0]:\n",
        "            label = 'ambiguous'\n",
        "        else:\n",
        "            label = 'irrelevant'\n",
        "        irr_record = {\n",
        "            \"question\": q,\n",
        "            \"context\": irr_text,\n",
        "            \"score\": irr_score,\n",
        "            \"label\": label\n",
        "            }\n",
        "        dataset.append(irr_record)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "thresholds = [25, 60]\n",
        "qc = pd.read_csv(DATA_DIR+'/arxiv_finetuning_qa.csv')\n",
        "print(qc.shape)\n",
        "\n",
        "\n",
        "data = build_records(qc, thresholds)\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Saving Dataset\n",
        "df.to_csv(DATA_DIR+'/arxiv_finetuning_dataset.csv', index=False, escapechar='\\\\')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH_BEk0ILSO-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "aa7dd96f-139c-4375-bf60-aed193390705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3594, 4)\n",
            "label\n",
            "irrelevant    1798\n",
            "relevant      1198\n",
            "ambiguous      598\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What two content modeling approaches are compa...   \n",
              "1  What two content modeling approaches are compa...   \n",
              "2  What two content modeling approaches are compa...   \n",
              "3  What are the main advantages of using word emb...   \n",
              "4  What are the main advantages of using word emb...   \n",
              "\n",
              "                                             context  score       label  \n",
              "0  Document Embedding for Scientiﬁc Articles: Eﬃc...     95    relevant  \n",
              "1  The ongoing research in machine learning empha...     10  irrelevant  \n",
              "2  The Great Wall of China is one of the most ico...      0  irrelevant  \n",
              "3  the expense of 3.7 times more memory requireme...     85    relevant  \n",
              "4  The evolution of natural language processing h...     45   ambiguous  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77ab20d6-2e47-46ab-b539-805040b19715\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What two content modeling approaches are compa...</td>\n",
              "      <td>Document Embedding for Scientiﬁc Articles: Eﬃc...</td>\n",
              "      <td>95</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What two content modeling approaches are compa...</td>\n",
              "      <td>The ongoing research in machine learning empha...</td>\n",
              "      <td>10</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What two content modeling approaches are compa...</td>\n",
              "      <td>The Great Wall of China is one of the most ico...</td>\n",
              "      <td>0</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the main advantages of using word emb...</td>\n",
              "      <td>the expense of 3.7 times more memory requireme...</td>\n",
              "      <td>85</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the main advantages of using word emb...</td>\n",
              "      <td>The evolution of natural language processing h...</td>\n",
              "      <td>45</td>\n",
              "      <td>ambiguous</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77ab20d6-2e47-46ab-b539-805040b19715')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77ab20d6-2e47-46ab-b539-805040b19715 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77ab20d6-2e47-46ab-b539-805040b19715');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ddcbbbdc-b992-46af-a0cb-254a3ddec8f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ddcbbbdc-b992-46af-a0cb-254a3ddec8f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ddcbbbdc-b992-46af-a0cb-254a3ddec8f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3594,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1157,\n        \"samples\": [\n          \"What are the key contributions of BERT in relation to bidirectional pre-training and its performance on NLP tasks compared to previous models?\",\n          \"What is the main contribution of the Zero-shot-CoT prompting method, and how does it compare to the Few-shot-CoT and standard zero-shot approaches in terms of performance on reasoning tasks?\",\n          \"What is the main objective of training the encoders in the context of retrieval, and what types of negative examples are considered for this training?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2967,\n        \"samples\": [\n          \"The Great Wall of China is one of the most iconic structures in the world, stretching over 13,000 miles across northern China. Originally built to protect against invasions, it showcases ancient engineering techniques and has become a symbol of China's historical resilience and cultural heritage. The wall consists of various materials, including earth, wood, bricks, and stone, and its construction spanned several dynasties, reflecting the evolving architectural styles of the time.\",\n          \"The Great Wall of China is one of the most remarkable architectural feats in history. Stretching over 13,000 miles, it was built to protect Chinese states from invasions and raids. The wall features various materials, including earth, wood, bricks, and stone, depending on the region and the time period of construction. Today, it stands as a UNESCO World Heritage site and a symbol of China's enduring strength and cultural heritage.\",\n          \"The Great Wall of China is an iconic symbol of Chinese history and culture. Stretching over 13,000 miles, it was originally built to protect against invasions and raids. Construction began as early as the 7th century BC, and various dynasties contributed to its expansion and fortification over the centuries. Today, it stands as a UNESCO World Heritage site and attracts millions of tourists each year.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 39,\n        \"min\": 0,\n        \"max\": 100,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          95,\n          75,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\",\n          \"ambiguous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "df = pd.read_csv(DATA_DIR+'/arxiv_finetuning_dataset.csv')\n",
        "print(df.shape)\n",
        "df.drop_duplicates()\n",
        "\n",
        "counts = df['label'].value_counts()\n",
        "print(counts)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuUzKVF6cLfz"
      },
      "source": [
        "### Under Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tvh-blu-cbLz"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample, shuffle\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Class distribution before balancing:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "df_relevant = df[df['label'] == 'relevant']\n",
        "df_irrelevant = df[df['label'] == 'irrelevant']\n",
        "df_ambiguous = df[df['label'] == 'ambiguous']\n",
        "\n",
        "min_size = len(df_ambiguous)\n",
        "\n",
        "df_relevant_downsampled = resample(df_relevant, replace=False, n_samples=min_size, random_state=123)\n",
        "df_irrelevant_downsampled = resample(df_irrelevant, replace=False, n_samples=min_size, random_state=123)\n",
        "\n",
        "df_dnbalanced = pd.concat([df_relevant_downsampled, df_irrelevant_downsampled, df_ambiguous])\n",
        "\n",
        "df_dnbalanced = shuffle(df_dnbalanced, random_state=123)\n",
        "\n",
        "\n",
        "# Save Under Sampled Data\n",
        "df_dnbalanced.to_csv(DATA_DIR+'/arxiv_finetuning_dataset_dnbalanced.csv', index=False, escapechar='\\\\')\n",
        "\n",
        "print(\"Class distribution after balancing:\")\n",
        "print(df_dnbalanced['label'].value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dnbalanced = pd.read_csv(DATA_DIR+'/arxiv_finetuning_dataset_dnbalanced.csv')\n",
        "counts = df_dnbalanced['label'].value_counts()\n",
        "print(counts)\n",
        "df_dnbalanced.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "zscG3eQnDMwC",
        "outputId": "0feae446-2592-4c58-89a2-7e424b8f1890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "relevant      598\n",
            "irrelevant    598\n",
            "ambiguous     598\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What retrieval model is used across all differ...   \n",
              "1  What were the two choices of the pre-training ...   \n",
              "2  What potential improvement is suggested for en...   \n",
              "3  What modification is made to the attention lay...   \n",
              "4  What findings were derived from the ablation s...   \n",
              "\n",
              "                                             context  score       label  \n",
              "0  the same, and Acc measures whether the predict...    100    relevant  \n",
              "1  et al., 2017) Sparse Retr.+DocReader N/A - 20....    100    relevant  \n",
              "2  improved by weighing them with the TFIDF value...     85    relevant  \n",
              "3  The Great Wall of China is one of the most ico...      0  irrelevant  \n",
              "4  The Great Wall of China is one of the most ico...      0  irrelevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5de75879-d6af-4652-87ca-4a67d65ff709\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What retrieval model is used across all differ...</td>\n",
              "      <td>the same, and Acc measures whether the predict...</td>\n",
              "      <td>100</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What were the two choices of the pre-training ...</td>\n",
              "      <td>et al., 2017) Sparse Retr.+DocReader N/A - 20....</td>\n",
              "      <td>100</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What potential improvement is suggested for en...</td>\n",
              "      <td>improved by weighing them with the TFIDF value...</td>\n",
              "      <td>85</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What modification is made to the attention lay...</td>\n",
              "      <td>The Great Wall of China is one of the most ico...</td>\n",
              "      <td>0</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What findings were derived from the ablation s...</td>\n",
              "      <td>The Great Wall of China is one of the most ico...</td>\n",
              "      <td>0</td>\n",
              "      <td>irrelevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5de75879-d6af-4652-87ca-4a67d65ff709')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5de75879-d6af-4652-87ca-4a67d65ff709 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5de75879-d6af-4652-87ca-4a67d65ff709');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3662eba9-80e2-43fb-93f6-339377627ee8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3662eba9-80e2-43fb-93f6-339377627ee8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3662eba9-80e2-43fb-93f6-339377627ee8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_dnbalanced",
              "summary": "{\n  \"name\": \"df_dnbalanced\",\n  \"rows\": 1794,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1044,\n        \"samples\": [\n          \"What were the findings regarding the frequency of answers generated by SELF-RAG compared to other models in terms of being included in the provided evidence, and what does SELF-RAG indicate when retrieved passages are not relevant?\",\n          \"What are the three different types of negative passages considered for training a high-quality encoder, and what is the benefit of re-using gold passages from the same mini-batch as negatives?\",\n          \"What is the main feature of Infini-attention that distinguishes it from the attention mechanism used in Transformer-XL, and how does it maintain context history?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1639,\n        \"samples\": [\n          \"The ongoing research in artificial intelligence emphasizes the importance of interpretability and transparency in model development. As large language models evolve, there is a growing recognition of the need for frameworks that allow users to understand decision-making processes. This shift is crucial for fostering trust and accountability in AI systems, especially in sensitive applications. \\n\\nCosine Similarity Score: 29.45%\",\n          \"z as a latent variable and marginalize over all possible documents z, yielding p(y | x) = X z\\u2208Z p(y | z, x) p(z | x). (1) 3.2. Model architecture We now describe the two key components: the neural knowledge retriever, which models p(z | x), and the knowledge-augmented encoder, which models p(y | z, x). Knowledge Retriever The retriever is de\\ufb01ned using a dense inner product model: p(z | x) = exp f(x, z) P z\\u2032 exp f(x, z\\u2032), f(x, z) = Embedinput(x)\\u22a4Embeddoc(z), where Embedinput and Embeddoc are embedding functions that map x and z respectively to d-dimensional vectors. The relevance score f(x, z) between x and z is de\\ufb01ned as the inner product of the vector embeddings. The retrieval distribution is the softmax over all relevance scores. We implement the embedding functions using BERT-style Transformers (Devlin et al., 2018). Following standard practices, we join spans of text by applying wordpiece tok- enization, separating them with [SEP] tokens, pre\\ufb01xing a [CLS] token, and appending a \\ufb01nal [SEP] token. joinBERT(x) = [CLS]x[SEP] joinBERT(x1, x2) = [CLS]x1[SEP]x2[SEP] As in Devlin et al. (2018), we pass this into a Transformer, which produces one vector for each token, including the vector corresponding to [CLS] which is used as a \\u201cpooled\\u201d representation of the sequence (denoted BERTCLS). Finally, we perform a linear projection to reduce the dimensionality of the vector, denoted as a projection matrix W: Embedinput(x) = WinputBERTCLS(joinBERT(x)) Embeddoc(z) = WdocBERTCLS(joinBERT(ztitle, zbody)) where ztitle is the document\\u2019s title and zbody is its body. We let \\u03b8 denote all parameters associated with the retriever, which include the Transformer and projection matrices. Knowledge-Augmented Encoder Given an input x and a retrieved document z, the knowledge-augmented encoder de\\ufb01nes p(y | z, x). We join x and z into a single sequence that we feed into a\",\n          \"In the realm of neural network architectures, the choice of layer types significantly impacts performance across various tasks. For instance, convolutional layers excel in capturing local patterns, while recurrent layers are adept at handling sequential dependencies. Recent innovations have also introduced hybrid models that leverage the strengths of both approaches, leading to enhanced feature extraction capabilities in complex datasets.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 0,\n        \"max\": 100,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          100,\n          15,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relevant\",\n          \"irrelevant\",\n          \"ambiguous\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UdWAt7TfSIa"
      },
      "source": [
        "### Over Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COUo9YZKbGZf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "print(\"Class distribution before balancing:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "df_relevant = df[df['label'] == 'relevant']\n",
        "df_irrelevant = df[df['label'] == 'irrelevant']\n",
        "df_ambiguous = df[df['label'] == 'ambiguous']\n",
        "\n",
        "def augment_text(text):\n",
        "    words = text.split()\n",
        "    if len(words) > 1:\n",
        "        # Randomly choose a modification method\n",
        "        mod_type = random.choice(['reverse', 'swap', 'insert'])\n",
        "        if mod_type == 'reverse':\n",
        "            index = random.randint(0, len(words) - 1)\n",
        "            words[index] = words[index][::-1]\n",
        "        elif mod_type == 'swap' and len(words) > 2:\n",
        "            idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "            words[idx1], words[idx2] = words[idx2], words[idx1]\n",
        "        elif mod_type == 'insert':\n",
        "            index = random.randint(0, len(words))\n",
        "            words.insert(index, random.choice(words))\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Number of samples to generate\n",
        "n_samples_irrelevant = len(df_irrelevant)\n",
        "n_samples_relevant = n_samples_irrelevant - len(df_relevant)\n",
        "n_samples_ambiguous = n_samples_irrelevant - len(df_ambiguous)\n",
        "\n",
        "new_relevant = df_relevant.sample(n=n_samples_relevant, replace=True).copy()\n",
        "new_relevant['question'] = new_relevant['question'].apply(augment_text)\n",
        "new_relevant['context'] = new_relevant['context'].apply(augment_text)\n",
        "\n",
        "new_ambiguous = df_ambiguous.sample(n=n_samples_ambiguous, replace=True).copy()\n",
        "new_ambiguous['question'] = new_ambiguous['question'].apply(augment_text)\n",
        "new_ambiguous['context'] = new_ambiguous['context'].apply(augment_text)\n",
        "\n",
        "df_upbalanced = pd.concat([df_irrelevant, df_relevant, df_ambiguous, new_relevant, new_ambiguous])\n",
        "\n",
        "# Shuffle the balanced DataFrame\n",
        "df_upbalanced = shuffle(df_upbalanced, random_state=123)\n",
        "# Save Over Sampled Data\n",
        "df_upbalanced.to_csv(DATA_DIR+'/arxiv_finetuning_dataset_upbalanced.csv', index=False, escapechar='\\\\')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_upbalanced = pd.read_csv(DATA_DIR+'/arxiv_finetuning_dataset_upbalanced.csv')\n",
        "counts = df_upbalanced['label'].value_counts()\n",
        "print(counts)\n",
        "df_upbalanced.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "JUEsacE_DxiY",
        "outputId": "9b6630f7-814b-4666-cfcf-4a44b236fc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "relevant      1798\n",
            "ambiguous     1798\n",
            "irrelevant    1798\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  What modifications can be made to the odd-size...   \n",
              "1  What is the main advantage of using a fused k-...   \n",
              "2  What are the differences in memory usage, calc...   \n",
              "3  What notable misclassifications are revealed b...   \n",
              "4  What is the main question being investigated r...   \n",
              "\n",
              "                                             context  score      label  \n",
              "0  if end do end if end function Odd-size merging...     85   relevant  \n",
              "1  The development of advanced kernel methods has...     25  ambiguous  \n",
              "2  In the realm of natural language processing, v...     30  ambiguous  \n",
              "3  In the realm of machine learning, the evaluati...     25  ambiguous  \n",
              "4  or an end of questions token. 4.2 Question Ans...     85   relevant  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59fde14c-446e-4434-8d3d-a478a5f33cb6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>context</th>\n",
              "      <th>score</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What modifications can be made to the odd-size...</td>\n",
              "      <td>if end do end if end function Odd-size merging...</td>\n",
              "      <td>85</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the main advantage of using a fused k-...</td>\n",
              "      <td>The development of advanced kernel methods has...</td>\n",
              "      <td>25</td>\n",
              "      <td>ambiguous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the differences in memory usage, calc...</td>\n",
              "      <td>In the realm of natural language processing, v...</td>\n",
              "      <td>30</td>\n",
              "      <td>ambiguous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What notable misclassifications are revealed b...</td>\n",
              "      <td>In the realm of machine learning, the evaluati...</td>\n",
              "      <td>25</td>\n",
              "      <td>ambiguous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the main question being investigated r...</td>\n",
              "      <td>or an end of questions token. 4.2 Question Ans...</td>\n",
              "      <td>85</td>\n",
              "      <td>relevant</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59fde14c-446e-4434-8d3d-a478a5f33cb6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-59fde14c-446e-4434-8d3d-a478a5f33cb6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-59fde14c-446e-4434-8d3d-a478a5f33cb6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6eb3ef6f-15db-436b-b846-b3571cd816ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6eb3ef6f-15db-436b-b846-b3571cd816ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6eb3ef6f-15db-436b-b846-b3571cd816ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_upbalanced",
              "summary": "{\n  \"name\": \"df_upbalanced\",\n  \"rows\": 5394,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2969,\n        \"samples\": [\n          \"What are the main and regarding biases in the training data of models like GPT-3, concerns what specific categories of bias were analyzed in the preliminary study?\",\n          \"What are the additional steps involved in the RAG-Fusion process compared to the standard retrieval-augmented generation (RAG) method, and how does reciprocal rank fusion contribute to document scoring and reranking?\",\n          \"What does the IP57 rating signify for the IM72D128 microphone, and what advantages does its the sealed design provide?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4781,\n        \"samples\": [\n          \"The evolution of chatbots often emphasizes the importance of user experience and engagement. Many developers are exploring ways to enhance interaction through improved natural language processing capabilities, enabling more intuitive conversations. Additionally, advancements in multilingual support are becoming a focal point, as developers recognize the need to cater to a diverse user base across various regions. These trends reflect a broader commitment to making technology more accessible and user-friendly.  \\nCosine Similarity Score: 29.47%\",\n          \"The rapid evolution of hardware capabilities has significantly influenced the development of computational techniques across various fields. Innovations in parallel processing have led to more efficient algorithms and can handle large datasets, facilitating advancements in machine learning that data analysis. This shift towards utilizing high-performance computing resources has opened new avenues for applications requiring extensive data manipulation and real-time processing. Cosine Similarity Score: 28.47%\",\n          \"The evolution of natural language processing has seen a significant emphasis on benchmarking models against standardized datasets. These benchmarks often reveal the strengths and weaknesses of various architectures, highlighting the importance of cificeps-ksat training and the role of transfer learning in enhancing model performance across diverse applications. Researchers continually investigate how different model configurations impact the overall effectiveness in real-world scenarios. Cosine Similarity Score: 29.76%\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36,\n        \"min\": 0,\n        \"max\": 100,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          85,\n          80,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"relevant\",\n          \"ambiguous\",\n          \"irrelevant\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare for HuggingFace"
      ],
      "metadata": {
        "id": "opkEyHqSzuR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset_path = \"/content/drive/MyDrive/Datasets/arxiv_finetuning_dataset_upbalanced.csv\"\n",
        "dataset_path = \"/content/drive/MyDrive/Datasets/arxiv_finetuning_dataset_dnbalanced.csv\"\n",
        "df = pd.read_csv(dataset_path)\n",
        "print(df.shape)\n",
        "\n",
        "df = df.to_dict(orient='records')\n",
        "\n",
        "with open(\"./train.jsonl\", \"w\") as f:\n",
        "    for line in df:\n",
        "        f.write(json.dumps(line) + '\\n')"
      ],
      "metadata": {
        "id": "fAl4q4Jizy05"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBodjgMotH/fyphNQBNEOP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}